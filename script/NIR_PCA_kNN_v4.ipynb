{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIR spectroscopy : PCA LDA machine loogistic regression / Support Vector Machine\n",
    "- メランチ４種類のスペクトルデータを読み込んで解析を進めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIR data from Spectrum 100N\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd .options.display.max_rows = 10\n",
    "df = pd.read_csv('../../../GitHubData/DataScience_AI/data/Spectroscopy/Data_of_4_Meranti species.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, plotting all the data to see their trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "wavnum = np.array(df.columns).astype('float')\n",
    "spectrum=df.transpose()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "spectrum.plot(ax=ax, legend=False)\n",
    "ax.set_title(\"All measured spectra\", fontsize=16)\n",
    "ax.set_xlabel(\"wavenumber cm-1\", fontsize=16)\n",
    "ax.grid()\n",
    "ax.tick_params(labelsize=14) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 文献によると \n",
    "- 800-1100nm いずれのバンドも非常に弱いのでこの領域は 透過性にすぐれている.非破壊分析，無侵襲分析に適 し，近赤外の医学応用や選果機などはこの領域を利用\n",
    "- 1100-1800nm で，この領域 には XH 伸縮振動の第一，第二倍音のほかに多くの結 合音が観測される.近赤外分光法を用いた基礎研究， 応用研究に最もよく用いられる領域\n",
    "- 1800-2500nm で，ここで観測されるバンドのほ とんどは結合音によるものである.この領域はかなり 透過性が悪い.\n",
    "> (ここから原文）近赤外域は3つの領域に分けて考えると都合がよい. 第一の領域は800-1100nm の領域で，この領域で観 測されるバンドは，基準振動の高次倍音(CH，OH， NH 伸縮振動の第2，第3，第4倍音など)と電子吸収 である.いずれのバンドも非常に弱いのでこの領域は 透過性にすぐれている.非破壊分析，無侵襲分析に適 し，近赤外の医学応用や選果機などはこの領域を利用 している.第二の領域は1100-1800nm で，この領域 には XH 伸縮振動の第一，第二倍音のほかに多くの結 合音が観測される.近赤外分光法を用いた基礎研究， 応用研究に最もよく用いられる領域である.第三の領 域は1800-2500nm で，ここで観測されるバンドのほとんどは結合音によるものである.この領域はかなり 透過性が悪い. (近藤みゆき　金赤外分光法による食品の化学的分析、名古屋文理大学紀要、7,23-28 (2007))\n",
    "\n",
    "\n",
    "\n",
    "| nm   | nm       | cm   | cm       | cm-1  |\n",
    "| ---- | -------- | ---- | -------- | ----- |\n",
    "| 800  | 1.00E-09 | 100  | 8.00E-05 | 12500 |\n",
    "| 1100 | 1.00E-09 | 100  | 1.10E-04 | 9091  |\n",
    "| 1800 | 1.00E-09 | 100  | 1.80E-04 | 5556  |\n",
    "| 2500 | 1.00E-09 | 100  | 2.50E-04 | 4000  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate 2nd derivative spectra by Savitzky-Golay algorithm. Window-size = 61, fitting function order = 3, seems reasonable. \n",
    "- ここからは２次微分をしてスペクトルの規格化をおこなう。\n",
    "> - (1) A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of Data by Simplified Least Squares Procedures. Analytical Chemistry, 1964, 36 (8), pp 1627-1639. (2) Numerical Recipes 3rd Edition: The Art of Scientific Computing W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery Cambridge University Press ISBN-13: 9780521880688\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.process import savitzky_golay\n",
    "wavnum = np.array(df.columns).astype('float')\n",
    "y1 = df.iloc[10]\n",
    "y2 = savitzky_golay(y1,61,3,2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot(wavnum ,y2*500+0.5)\n",
    "ax.plot(wavnum ,y1.T+0.6)\n",
    "ax.set_title(\"original and its 2nd derivative spectra from  10th sample\", fontsize=16)\n",
    "ax.set_xlabel(\"wavenumber cm-1\", fontsize=16)\n",
    "ax.grid()\n",
    "ax.tick_params(labelsize=14) \n",
    "ax.invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 前スペクトルの微分を行いプロットする\n",
    "- 機械学習用のデータとしてエクセル形式で保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_2nd_deriv = []\n",
    "for n in range(df.shape[0]):\n",
    "    y = df.iloc[n]\n",
    "    spectra_2nd_deriv.append(savitzky_golay(y,61,3,2))\n",
    "X_data = np.array(spectra_2nd_deriv)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "plt.plot(wavnum,X_data.T)\n",
    "ax.set_title(\"All 2nd derivative spectra savitzy_golay param (61,3,2)\", fontsize=16)\n",
    "ax.set_xlabel(\"wavenumber cm-1\", fontsize=16)\n",
    "ax.grid()\n",
    "ax.tick_params(labelsize=14) \n",
    "ax.invert_xaxis()\n",
    "plt.show()\n",
    "\n",
    "second_dev=pd.DataFrame(X_data ,columns=wavnum,index=df.index)\n",
    "second_dev.to_excel('../../../GitHubData/Datascience_AI/data/Spectroscopy/2nd_Meranti_.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ここから下のスクリプトがテキストにあるものと同じ、データは二次微分データから使うように変更したもの。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA analyses : wavenuber range  8000-4000 cm-1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "second_dev_spectrum=pd.read_excel('../../../GitHubData/Datascience_AI/data/Spectroscopy/2nd_Meranti_.xlsx', index_col=0)\n",
    "#\n",
    "wv_max=8000\n",
    "wv_min=4000\n",
    "#\n",
    "wvmax=int((10000-wv_max)/2)\n",
    "wvmin=int((10000-wv_min)/2)\n",
    "wvnum=second_dev_spectrum.columns[wvmax:wvmin]\n",
    "X = second_dev_spectrum.iloc[:,wvmax:wvmin]\n",
    "X = X*10e3  # \n",
    "\n",
    "target_names=np.unique(second_dev_spectrum.index)\n",
    "tmp = pd.get_dummies(second_dev_spectrum.index)\n",
    "X_category = tmp.values.argmax(1) # make strings into numbers 0,1,2,...\n",
    "sp_names = second_dev_spectrum.index\n",
    "\n",
    "title = 'PCA from '+str(wvmax)+'-'+str(wvmax)+'cm-1 region' \n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "        \n",
    "fig, axes = plt.subplots(nrows=3, figsize=(10,15))\n",
    "#　寄与率\n",
    "axes[0].bar(np.arange(1,11,1), pca.explained_variance_ratio_, align = \"center\")\n",
    "axes[0].set_title(\"Screeplot of \"+title)\n",
    "axes[0].set_xlabel(\"components\")\n",
    "axes[0].set_ylabel(\"contribution\")\n",
    "# ２次微分曲線\n",
    "axes[1].plot(wvnum,X.T,linewidth = 2 ) ## x 10e3 \n",
    "axes[1].set_title(\"2nd dev spectra of \"+title)\n",
    "axes[1].invert_xaxis()\n",
    "# 因子付加量\n",
    "loadings = pca.components_*np.c_[np.sqrt(pca.explained_variance_)]\n",
    "axes[2].plot(wvnum,loadings[0],linewidth = 2, label='PC1 loading')\n",
    "axes[2].plot(wvnum,loadings[1],linewidth = 2, label='PC2 loading' )\n",
    "axes[2].plot(wvnum,loadings[2],linewidth = 2, label='PC3 loading' )\n",
    "axes[2].set_title(\"Loading of \"+title)\n",
    "axes[2].invert_xaxis()\n",
    "axes[2].legend()\n",
    "plt.show()\n",
    "        \n",
    "#PCA 3D plot\n",
    "colors = ['r', 'g', 'b','y' ]\n",
    "# fig = plt.figure(1, figsize=(8, 6))\n",
    "# plt.clf()\n",
    "# ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "# plt.cla()\n",
    "# lw=5\n",
    "# for color, i, target_name in zip(colors, list(range(max(X_category)+1)), target_names):\n",
    "#     ax.scatter(X_r[X_category==i, 0], X_r[X_category==i, 1], X_r[X_category==i, 2], color=color, lw=lw, label=target_name) \n",
    "# ax.set_xlabel('PC1')\n",
    "# ax.set_ylabel('PC2')\n",
    "# ax.set_zlabel('PC3')\n",
    "# ax.set_title(title, fontsize=20)\n",
    "# ax.legend(bbox_to_anchor=(1.1, 0.8), shadow=False, scatterpoints=1)\n",
    "         \n",
    "# PCA\n",
    "fig, axes = plt.subplots(ncols=2,figsize=(10,4))\n",
    "lw = 2 # line width\n",
    "for color, i, target_name in zip(colors, list(range(max(X_category)+1)), target_names):\n",
    "    axes[0].scatter(X_r[X_category == i, 0], X_r[X_category == i, 1], color=color,lw=lw,label=target_name)\n",
    "axes[0].set_title(title)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "\n",
    "for color, i, target_name in zip(colors, list(range(max(X_category)+1)), target_names):\n",
    "    axes[1].scatter(X_r[X_category == i, 1], X_r[X_category == i, 2], color=color, lw=lw,label=target_name)\n",
    "axes[1].legend(bbox_to_anchor=(1.4, 1.1), shadow=False, scatterpoints=1)\n",
    "axes[1].set_title(title)\n",
    "axes[1].set_xlabel('PC2')\n",
    "axes[1].set_ylabel('PC3')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from mlxtend.plotting import plot_decision_regions\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,X_category, test_size=0.3, random_state=0)\n",
    "\n",
    "# LDA=LinearDiscriminantAnalysis(n_components=3)\n",
    "# x_train_lda=LDA.fit_transform(X_train, y_train)\n",
    "# X_test_lda = LDA.transform(X_test)\n",
    "# lr = LogisticRegression()\n",
    "\n",
    "# lr.fit(x_train_lda, y_train)\n",
    "# y_pred = lr.predict(X_test_lda)\n",
    "# print('Accuracy: %.2f' % accuracy_score(y_test,y_pred))\n",
    "\n",
    "\n",
    "# title = \"LDA from 9000-8000 cm-1 region\"\n",
    "\n",
    "# #PCA 3D plot\n",
    "# colors = ['r', 'g', 'b','y' ]\n",
    "# fig = plt.figure(1, figsize=(8, 6))\n",
    "# plt.clf()\n",
    "# ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "# plt.cla()\n",
    "# lw=5\n",
    "# for color, i, target_name in zip(colors, list(range(max(y_train)+1)), target_names):\n",
    "#     ax.scatter(x_train_lda[y_train==i, 0], x_train_lda[y_train==i, 1], x_train_lda[y_train==i, 2], color=color, lw=lw, label=target_name) \n",
    "# ax.set_xlabel('LD1')\n",
    "# ax.set_ylabel('LD2')\n",
    "# ax.set_zlabel('LD3')\n",
    "# ax.set_title(title, fontsize=20)\n",
    "# ax.legend(bbox_to_anchor=(1.1, 0.8), shadow=False, scatterpoints=1)\n",
    "         \n",
    "# # PCA\n",
    "# fig, axes = plt.subplots(ncols=2,figsize=(10,4))\n",
    "# lw = 2 # line width\n",
    "# for color, i, target_name in zip(colors, list(range(max(y_train)+1)), target_names):\n",
    "#     axes[0].scatter(x_train_lda[y_train == i, 0], x_train_lda[y_train == i, 1], color=color,lw=lw,label=target_name)\n",
    "# axes[0].set_title(title)\n",
    "# axes[0].set_xlabel('LD1')\n",
    "# axes[0].set_ylabel('LD2')\n",
    "\n",
    "# for color, i, target_name in zip(colors, list(range(max(y_train)+1)), target_names):\n",
    "#     axes[1].scatter(x_train_lda[y_train == i, 1], x_train_lda[y_train == i, 2], color=color, lw=lw,label=target_name)\n",
    "# axes[1].legend(bbox_to_anchor=(1.4, 1.1), shadow=False, scatterpoints=1)\n",
    "# axes[1].set_title(title)\n",
    "# axes[1].set_xlabel('LD2')\n",
    "# axes[1].set_ylabel('LD3')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from mlxtend.plotting import plot_decision_regions\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# second_dev_spectrum=pd.read_excel('../../../GitHubData/Datascience_AI/data/Spectroscopy/2nd_Meranti_.xlsx', index_col=0)\n",
    "\n",
    "# wv_max=9000\n",
    "# wv_min=8000\n",
    "\n",
    "# wvmax=int((10000-wv_max)/2)\n",
    "# wvmin=int((10000-wv_min)/2)\n",
    "# wvnum=second_dev_spectrum.columns[wvmax:wvmin]\n",
    "# X = second_dev_spectrum.iloc[:,wvmax:wvmin]\n",
    "# X = X*10e3  # \n",
    "\n",
    "# target_names=np.unique(second_dev_spectrum.index)\n",
    "# tmp = pd.get_dummies(second_dev_spectrum.index)\n",
    "# X_category = tmp.values.argmax(1) # make strings into numbers 0,1,2,...\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, X_category, test_size=0.3, random_state=0)\n",
    "\n",
    "# LDA=LinearDiscriminantAnalysis(n_components=3)\n",
    "# x_train_lda=LDA.fit_transform(X_train, y_train)\n",
    "# x_test_lda = LDA.transform(X_test)\n",
    "\n",
    "# lr = LogisticRegression()\n",
    "\n",
    "# lr.fit(x_train_lda, y_train)\n",
    "# y_pred = lr.predict(x_test_lda)\n",
    "\n",
    "\n",
    "# title = 'LDA from '+str(wvmax)+'-'+str(wvmax)+'cm-1 region: Accuuracy:%.2f' % accuracy_score(y_test,y_pred) \n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10,4))\n",
    "# ax.plot(wvnum,X.T,linewidth = 2 ) ## x 10e3 \n",
    "# ax.set_title(\"2nd dev spectra of \"+title)\n",
    "# ax.invert_xaxis()\n",
    "\n",
    "# fig, ax = plt.subplots(ncols=2, figsize=(10,4))\n",
    "# ds=[(x_train_lda[:,0:2], y_train),(x_test_lda[:,0:2], y_test)]\n",
    "# for i in range(len(ds)):\n",
    "#     plot_decision_regions(ds[i][0], ds[i][1], clf=lr,ax=ax[i])\n",
    "#     ax[i].set_xlabel('LD 1')\n",
    "#     ax[i].set_ylabel('LD 2')\n",
    "#     ax[i].legend(loc='lower left')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# x_train_lda[:,0:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_NIR(fl, wmax, wmin, svgo, method,ncomp,classifier):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from common.process import savitzky_golay\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.svm import SVC\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    from mlxtend.plotting import plot_decision_regions\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    %matplotlib inline\n",
    "\n",
    "    df = pd.read_csv(fl, header=0, index_col=0)\n",
    "    wavnum = np.array(df.columns).astype('float')\n",
    "    spectrum=df.transpose()\n",
    "    spectra_2nd_deriv = []\n",
    "    for n in range(df.shape[0]):\n",
    "        y = df.iloc[n]\n",
    "        spectra_2nd_deriv.append(savitzky_golay(y,svgo[0],svgo[1],svgo[2]))\n",
    "    X_data = np.array(spectra_2nd_deriv)\n",
    "\n",
    "    # make database for machine learning\n",
    "    second_dev=pd.DataFrame(X_data ,columns=wavnum,index=df.index)\n",
    "    target_names=np.unique(second_dev.index)\n",
    "    tmp = pd.get_dummies(second_dev.index)\n",
    "    #\n",
    "    wv_max=wmax\n",
    "    wv_min=wmin\n",
    "    #\n",
    "    wvmax=int((10000-wv_max)/2)\n",
    "    wvmin=int((10000-wv_min)/2)\n",
    "    wvnum=second_dev.columns[wvmax:wvmin]\n",
    "    X = second_dev.iloc[:,wvmax:wvmin]\n",
    "    sc = StandardScaler()\n",
    "\n",
    "  \n",
    "    X = sc.fit_transform(X)  # \n",
    "    X_category = tmp.values.argmax(1) # make strings into numbers 0,1,2,...\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, X_category, test_size=0.3, random_state=0)\n",
    "\n",
    "    target_names=np.unique(second_dev.index)\n",
    "    tmp = pd.get_dummies(second_dev.index)\n",
    "    X_category = tmp.values.argmax(1) # make strings into numbers 0,1,2,...\n",
    "    sp_names = second_dev.index\n",
    "    if method=='pca':\n",
    "        title = 'PCA from '+str(wmax)+'-'+str(wmin)+'cm-1 region'\n",
    "        pca = PCA(n_components=ncomp)\n",
    "        x_train_d = pca.fit_transform(X_train)\n",
    "        x_test_d = pca.transform(X_test)\n",
    "        accum_val=pca.explained_variance_ratio_\n",
    "        loadings = pca.components_*np.c_[np.sqrt(pca.explained_variance_)]\n",
    "        plot_spectrum(wvnum,X.T,ncomp,accum_val,loadings,title)\n",
    "        \n",
    "    elif method=='lda':\n",
    "        #ncomp=3\n",
    "        title = 'LDA from '+str(wmax)+'-'+str(wmin)+'cm-1 region'\n",
    "        LDA=LinearDiscriminantAnalysis(n_components=2,store_covariance=True)\n",
    "        x_train_d =LDA.fit_transform(X_train, y_train)\n",
    "        accum_val=LDA.explained_variance_ratio_\n",
    "        x_test_d = LDA.transform(X_test)\n",
    "        loadings = LDA.coef_\n",
    "        plot_spectrum(wvnum, X.T,2,accum_val,loadings,title)        \n",
    "    else:\n",
    "        print('please specify method of analysis PCA or LDA')\n",
    "        \n",
    "    if classifier=='lr':\n",
    "        print('Logistic Regression is selected')\n",
    "        myclf = LogisticRegression()\n",
    "        \n",
    "    elif classifier == 'svc':\n",
    "        print('Support Vector Machine is selected')\n",
    "        myclf = SVC()\n",
    "        \n",
    "    else:\n",
    "        print('Please select one of the classifier (lr or svc)')\n",
    "        \n",
    "    myclf.fit(x_train_d, y_train)\n",
    "    y_pred = myclf.predict(x_test_d)\n",
    "    title = str(wmax)+'-'+str(wmin)+'cm-1 region: Accuuracy:%.2f' % accuracy_score(y_test,y_pred) \n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(10,4))\n",
    "    \n",
    "\n",
    "#for i in range(len(ds)):\n",
    "    value=0.5\n",
    "    width=1\n",
    "    plot_decision_regions(x_train_d, y_train,feature_index=[0,1], \\\n",
    "                        filler_feature_values={2: value, 3:value, 4:value},\\\n",
    "                        filler_feature_ranges={2: width, 3: width, 4:width}, \\\n",
    "                          clf=myclf,ax=ax[0],zoom_factor=1)\n",
    "    ax[0].set_xlabel('comp 1')\n",
    "    ax[0].set_ylabel('comp 2')\n",
    "    ax[0].legend(loc='lower left')\n",
    "    ax[0]\n",
    "#fcommpo1 and comp 3\n",
    "    value=0.3\n",
    "    width=10\n",
    "    \n",
    "    plot_decision_regions(x_train_d, y_train,feature_index=[0,2], \\\n",
    "                        filler_feature_values={1: value, 3:value, 4:value},\\\n",
    "                        filler_feature_ranges={1: width, 3: width, 4:width}, \\\n",
    "                          clf=myclf,ax=ax[1],zoom_factor=1)\n",
    "    ax[1].set_xlabel('comp 1')\n",
    "    ax[1].set_ylabel('comp 3')\n",
    "    ax[1].legend(loc='lower left')\n",
    "    ax[1]\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_spectrum(x, y, ncomp, accum_val,loadings,title):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    fig, axes = plt.subplots(nrows=3, figsize=(10,12))\n",
    "    #　寄与率\n",
    "    axes[0].bar(np.arange(1,ncomp+1,1), accum_val, align = \"center\")\n",
    "    axes[0].set_title(\"Screeplot of \"+title)\n",
    "    axes[0].set_xlabel(\"components\")\n",
    "    axes[0].set_ylabel(\"contribution\")\n",
    "    # ２次微分曲線\n",
    "    axes[1].plot(x,y,linewidth = 2 ) ## x 10e3 \n",
    "    axes[1].set_title(\"2nd dev spectra of \"+title)\n",
    "    axes[1].invert_xaxis()\n",
    "    # 因子付加量    \n",
    "    axes[2].plot(x,loadings[0],linewidth = 2, label='comp 1 loading')\n",
    "    axes[2].plot(x,loadings[1],linewidth = 2, label='comp 2 loading' )\n",
    "    axes[2].plot(x,loadings[2],linewidth = 2, label='comp 3 loading' )\n",
    "    axes[2].set_title(\"Loading of \"+title)\n",
    "    axes[2].invert_xaxis()\n",
    "    axes[2].legend()\n",
    "    plt.tight_layout()\n",
    "    #fig.suptitle(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "# def plot_decision(tr_x,tr_l,te_x,te_l,clf_model):\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     from mlxtend.plotting import plot_decision_regions\n",
    "#     %matplotlib inline\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "##******************\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "fl='../../../GitHubData/DataScience_AI/data/Spectroscopy/Data_of_4_Meranti species.csv'\n",
    "analysis_NIR(fl,8000,4000,[51,3,2],'pca',5,'svc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## いまつくっているのはここ！　12月5日　日曜日"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.nir_ml import *\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "second_dev_spectrum=pd.read_excel('../../../GitHubData/Datascience_AI/data/Spectroscopy/2nd_Meranti_.xlsx', index_col=0)\n",
    "\n",
    "wv_max=8500\n",
    "wv_min=8000\n",
    "\n",
    "wvmax=int((10000-wv_max)/2)\n",
    "wvmin=int((10000-wv_min)/2)\n",
    "wvnum=second_dev_spectrum.columns[wvmax:wvmin]\n",
    "X = second_dev_spectrum.iloc[:,wvmax:wvmin]\n",
    "X = X*10e3  # \n",
    "\n",
    "target_names=np.unique(second_dev_spectrum.index)\n",
    "tmp = pd.get_dummies(second_dev_spectrum.index)\n",
    "X_category = tmp.values.argmax(1) # make strings into numbers 0,1,2,...\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, X_category, test_size=0.3, random_state=0)\n",
    "\n",
    "######################3\n",
    "\n",
    "\n",
    "\n",
    "step1 = list(zip([\"pca\", \"kNN\"], [PCA(n_components=2), KNeighborsClassifier()]))\n",
    "step2 = list(zip([\"pca\", \"lr\"], [PCA(n_components=2), LogisticRegression()]))\n",
    "step3 = list(zip([\"pca\", \"svc\"], [PCA(n_components=2), SVC()]))\n",
    "\n",
    "process_list=list(zip(step1,step2,step3))\n",
    "from sklearn import set_config\n",
    "pipes=[]\n",
    "for i in range(3):\n",
    "    proc=process_list[0][i],process_list[1][i]\n",
    "    pipes.append(Pipeline(proc))\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    x_train_d =pipes[i][0].fit_transform(X_train)\n",
    "    x_test_d = pipes[i][0].transform(X_test)\n",
    "    clf=pipes[i][1]\n",
    "    clf.fit(x_train_d, y_train)\n",
    "    y_pred = clf.predict(x_test_d)\n",
    "    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    X_combined = np.vstack((x_train_d, x_test_d))  # 全体プロット用\n",
    "    y_combined = np.hstack((y_train, y_test))  # 全体プロット用\n",
    "    plot_decision_regions(X_combined, y_combined, classifier=clf, resolution=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test), len(y_pred),len(X_combined),len(y_combined),len(x_train_d), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.nir_ml import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "second_dev_spectrum=pd.read_excel('../../../GitHubData/Datascience_AI/data/Spectroscopy/2nd_Meranti_.xlsx', index_col=0)\n",
    "\n",
    "wv_max=9500\n",
    "wv_min=9000\n",
    "wvmax=int((10000-wv_max)/2)\n",
    "wvmin=int((10000-wv_min)/2)\n",
    "wvnum=second_dev_spectrum.columns[wvmax:wvmin]\n",
    "X = second_dev_spectrum.iloc[:,wvmax:wvmin]\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "target_names=np.unique(second_dev_spectrum.index)\n",
    "tmp = pd.get_dummies(second_dev_spectrum.index)\n",
    "X_category = tmp.values.argmax(1) # make strings into numbers 0,1,2,...\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, X_category, test_size=0.3, random_state=0)\n",
    "#####################\n",
    "\n",
    "step1 = list(zip([\"pca\", \"kNN\"], [PCA(n_components=2), KNeighborsClassifier()]))\n",
    "step2 = list(zip([\"pca\", \"lr\"], [PCA(n_components=2), LogisticRegression()]))\n",
    "step3 = list(zip([\"pca\", \"svc\"], [PCA(n_components=2), SVC()]))\n",
    "\n",
    "process_list=list(zip(step1,step2,step3))\n",
    "from sklearn import set_config\n",
    "pipes=[]\n",
    "for i in range(3):\n",
    "    proc=process_list[0][i],process_list[1][i]\n",
    "    pipes.append(Pipeline(proc))\n",
    "\n",
    "for i in range(3):\n",
    "    x_train_d =pipes[i][0].fit_transform(X_train)\n",
    "    x_test_d = pipes[i][0].transform(X_test)\n",
    "    clf=pipes[i][1]\n",
    "    clf.fit(x_train_d, y_train)\n",
    "    y_pred = clf.predict(x_test_d)\n",
    "    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    X_combined = np.vstack((x_train_d, x_test_d))  # 全体プロット用\n",
    "    y_combined = np.hstack((y_train, y_test))  # 全体プロット用\n",
    "    plot_decision_regions(X_combined, y_combined, classifier=clf, resolution=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standard XOR data and classificatiion problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "X_xor=np.random.randn(150,2)\n",
    "Y_xor=np.logical_xor(X_xor[:,0]>0,X_xor[:,1]>0)\n",
    "Y_xor = np.where(Y_xor,1,-1)\n",
    "plt.scatter(X_xor[Y_xor==1,0],X_xor[Y_xor==1,1],c='b',marker='x',label='1')\n",
    "plt.scatter(X_xor[Y_xor==-1,0],X_xor[Y_xor==-1,1],c='y',marker='s',label='1')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_xor[:,0],X_xor[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.nir_ml import *\n",
    "clf=SVC()\n",
    "clf.fit(X_xor,Y_xor)\n",
    "plot_decision_regions(X_xor, Y_xor, classifier=clf, resolution=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.nir_ml import *\n",
    "clf=LogisticRegression()\n",
    "clf.fit(X_xor,Y_xor)\n",
    "plot_decision_regions(X_xor, Y_xor, classifier=clf, resolution=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.nir_ml import *\n",
    "clf=KNeighborsClassifier()\n",
    "clf.fit(X_xor,Y_xor)\n",
    "plot_decision_regions(X_xor, Y_xor, classifier=clf, resolution=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
